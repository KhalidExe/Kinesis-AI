# ğŸ–ï¸ Kinesis-AI | ÙƒÙŠÙ†ÙŠØ³ÙŠØ³

![Project Status](https://img.shields.io/badge/Status-Alpha_v0.1.0-orange?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.10_Required-3776AB?style=for-the-badge&logo=python&logoColor=white)
![OpenCV](https://img.shields.io/badge/Vision-OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
![MediaPipe](https://img.shields.io/badge/AI-MediaPipe-0099CC?style=for-the-badge&logo=google&logoColor=white)
![Platform](https://img.shields.io/badge/Platform-Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)

> **Touchless System Control using Computer Vision.**
> Kinesis-AI utilizes Google's MediaPipe to transform your hand gestures into powerful system commands, allowing you to control volume and playback speed without touching the keyboard.

---

## âš ï¸ Important Note (Read First)
**This project requires Python 3.10 to function correctly.**
Newer versions (like Python 3.13) are currently incompatible with MediaPipe dependencies. Please ensure you have Python 3.10 installed before running.

---

## ğŸ“¸ Demo
*(GIFs and Screenshots coming in v0.2.0...)*

---

## âš¡ Key Features

### ğŸ‘ï¸ AI-Powered Vision
- **Real-Time Tracking:** ğŸš€ High-performance hand detection running at 30+ FPS.
- **21-Point Skeleton:** Precision tracking of finger joints and palm orientation.
- **Dual Hand Support:** Intelligently distinguishes between Right and Left hands for different controls.

### ğŸ›ï¸ System Control (Roadmap)
- **Volume Master:** ğŸ”Š Pinch your **Right Hand** fingers to adjust system volume smoothly.
- **Speed Commander:** â© Pinch your **Left Hand** fingers to control video playback speed (YouTube/VLC).

### ğŸ› ï¸ Engineering
- **Privacy First:** All processing happens locally on your machine. No cloud data.
- **Optimized:** Lightweight code designed to run in the background with minimal CPU usage.

---

## ğŸ› ï¸ Tech Stack

* **Core:** Python 3.10.
* **Computer Vision:** OpenCV, MediaPipe (v0.10.9).
* **System Automation:** PyCaw (Audio), PyAutoGUI (Inputs).
* **Math:** NumPy.

---

## ğŸš€ How to Run (Locally)

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/KhalidExe/Kinesis-AI.git](https://github.com/KhalidExe/Kinesis-AI.git)
    cd Kinesis-AI
    ```

2.  **Set up Environment (Critical Step):**
    *Make sure you have Python 3.10 installed.*
    ```bash
    # Create virtual environment using Python 3.10
    py -3.10 -m venv venv
    
    # Activate it (Windows)
    .\venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Run the AI:**
    ```bash
    python main.py
    ```
    *Press 'q' on the keyboard to exit the application.*

---

## ğŸ“‚ Project Structure

```text
Kinesis-AI/
â”‚
â”œâ”€â”€ main.py              # The Brain: Main Loop & Vision Logic
â”œâ”€â”€ requirements.txt     # Locked Dependencies (Stable)
â”œâ”€â”€ README.md            # Documentation
â”‚
â””â”€â”€ venv/                # Virtual Environment (Excluded from Git)
```

## ğŸ”® Future Roadmap
- [x] v0.1.0: Core Skeleton Tracking & Environment Setup.

- [ ] v0.2.0: Right Hand Volume Control (PyCaw Integration).

- [ ] v0.3.0: Left Hand Playback Speed Control.

- [ ] v1.0.0: Visual HUD & Sci-Fi UI Overlay.

*Developed by **KhalidExe** Â© 2026*